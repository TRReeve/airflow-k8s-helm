# Default values for airflow-kubernetes.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
images:
  core:
    # The core airflow image for the webserver and scheduler components
    repository: reevedata/airflow-kubernetes
    pullPolicy: Always
    tag: 1.10.10
  # The docker repository location for your worker container.
  worker:
    repository: reevedata/airflow-kubernetes
    pullPolicy: Always
    tag: 1.10.10

airflow:
  example_dags:
    enable: true
  # Normally will be preferable to set this up for any production process
  remote_logging:
    enable: false
    # The name of a connection set up on your
    # Container for logging
    conn_name: logging
    # e.g s3
    conn_type: ""
    remote_logs_path: "cloud-data-k8s-staging-logs/airflow/logs"
    # A seperate secret is required that will be used to access
    # your logging bucket/screen/etc. This will contain a secret called "REMOTE_LOGGING_SECRET"
    # For example with AWS this would be ACCESS_KEY_ID:ACCESS_KEY_SECRET_ID.
    # This is then combined with the conn_type and the remote_logs path to create the uri that
    # airflow will use to build the connection.
    create_logging_secret: true
    remote_logs_secrets_filename: "logging-secrets"
    # Remote Path for your logging e.g s3://mylogs/airflow/logs)
    # If you are not providing your own secrets file with REMOTE_LOGGING_STRING included
    # then you can give the connection String that will be used for your logging connection.
    # This will be made into a secret.
    remote_logging_secret:

  webserver:
    enable: true
    replicas: 1
    ingress:
      enable: true
      host: airflow.example.mydomain.com
      annotations:
    resources:
      requests:
        cpu: "0.1"
        memory: "500Mi"
  scheduler:
    requests:
      cpu: "0.5"
      memory: "500Mi"

  secrets:
    create_secrets_file: true
    secret_file: "secrets-default"
    # The name of a secret object in the same namespace. This will contain
    # DB_PASSWORD, DB_HOST, REMOTE_LOGGING_STRING
    #    secret_file: my-secrets
    #    secret_file:

    # Any Further Secrets that need to be available in the environment can be added here.
    # IF PROVIDING FILE:
    # Secret only needs to a list form e.g
    #    extra_secrets:
    #      - Secret1
    #      - Secret2
    # IF SECRETS TO BE CREATED BY THIS HELM CHART (not recommended for production):
    # Secrets to be provided as a map e.g
    #      extra_secrets:
    #        Secret1: "admin"
    #        Secret2: "otherpass"
    extra_secrets: []

  worker:
    # Maximum amount of pods that can be created per scheduler heartbeat.
    pods_per_heartbeat: 5
    # Additional Environment variables that will be created on workers when they
    # Initialise
    worker_env_variables: []
  #Extra Variables that will be created in your webserver and scheduler containers.
  extra_variables: []

  db:
    # If Set to True creates a postgres database to act as
    # a backend for your airflow cluster.
    create_db: true
    protocol: postgresql+psycopg2
    username: admin
    host: airflow-default-db-svc
    password: testadminpass
    dbname: airflow
    port: 5432

